{
 "metadata": {
  "name": "",
  "signature": "sha256:dd63f31778942f20f8ca3f51d806ee0e77156562942347635ed6b7de024f49c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ".. _reproduce_shalek2013:\n",
      "\n",
      ".. currentmodule:: flotilla"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Accurate estimation of alternative splicing modalities"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "As shown in previous work (`Shalek+Satija et al 2013 <http://www.ncbi.nlm.nih.gov/pubmed/23685454>`_), the majority of alternative splicing in single cells is all or nothing - either the included isoform or the excluded isoform. Rarely are there genes whose included/excluded isoforms are held at a 50/50 ratio. However, it is unclear what fraction of transcripts are maintained at specific proportions across cells, and we aim to categorize these splicing events into five bins: included, middle, excluded, bimodal, and uniform.\n",
      "\n",
      "First, let's import the modules we'll need."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import os\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "sns.set(context='notebook', style='ticks')\n",
      "\n",
      "from flotilla.compute.splicing import ModalityEstimator, ModalityModel\n",
      "from flotilla.visualize.splicing import ModalitiesViz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we will initialize a ``ModalityEstimator`` for performing the calculations, and a ``ModalityViz`` for visualizing the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modality_estimator = ModalityEstimator(step=1, vmax=10)\n",
      "modality_visualizer = ModalitiesViz()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Next, let's plot the modalities we are modeling as `violin plots <http://en.wikipedia.org/wiki/Violin_plot>`_. We model splicing events' \"percent spliced-in\" or Psi/$\\Psi$ as following a `Beta distribution <http://en.wikipedia.org/wiki/Beta_distribution>`_:\n",
      "\n",
      "$$\n",
      "\\begin{align}\n",
      "\\Psi &\\sim \\text{Beta}\\left(\\alpha, \\beta\\right)\\\\\n",
      "&= \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}\n",
      "\\end{align}\n",
      "$$\n",
      "\n",
      "Where $B(\\alpha, \\beta)$ is the [Beta *function*](http://en.wikipedia.org/wiki/Beta_function), from which the Beta *distribution* gets its name,\n",
      "\n",
      "$$\n",
      "B\\left(\\alpha, \\beta\\right) = \\int_0^1 t^{\\alpha-1}(1-t)^{\\beta-1}dt\n",
      "$$\n",
      "\n",
      "The Beta distribution is perfect for splicing scores because ...\n",
      "\n",
      "1. It is continuous between 0 and 1, so any and all new splicing events we encounter are always valid by the model\n",
      "2. Its parameters, $\\alpha$ and $\\beta$ can be tuned to create the characteristic modalities we are interested in\n",
      "\n",
      "Specifically, we can model the *included*, *middle*, *excluded*, or *bimodal* modalities. In the plot below, note that only the first four are actually in the model, and that the uniform distribution was separately created. This is because the uniform distribution cannot be parameterized, it is exactly when $\\alpha=1$ and $\\beta=1$, and as every splicing event has exactly the same probability under the uniform distribution, $Pr_{\\text{Uniform}}(\\text{event})=1$, we will use the uniform distribution as our null model for testing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(2*5, 4))\n",
      "\n",
      "n = 10000\n",
      "\n",
      "# Use the last parameterization (we'll get to that next) in the model list of random variables \"rvs\"\n",
      "model_data = pd.DataFrame({model_name: model.rvs[-1].rvs(n) for model_name, model in modality_estimator.models.items()})\n",
      "model_params = pd.Series({model_name: model.rvs[-1].args for model_name, model in modality_estimator.models.items()})\n",
      "\n",
      "# Add the uniform distribution\n",
      "model_data['uniform'] = np.linspace(0, 1, num=n)\n",
      "\n",
      "# Reorder the columns\n",
      "columns_ordered = ['included', 'middle', 'bimodal', 'excluded', 'uniform']\n",
      "model_data = model_data.reindex(columns=columns_ordered)\n",
      "\n",
      "# Get modality colors\n",
      "colors = [modality_visualizer.modality_colors[m] for m in model_data.columns]\n",
      "\n",
      "# Rename the columns to include the alpha and beta parameters\n",
      "modality_with_params_renamer = {model_name: '{}\\n$\\\\alpha={:.2f}$\\n$\\\\beta={:.2f}$'.format(model_name, alpha, beta) \n",
      " for model_name, (alpha, beta) in model_params.iteritems()}\n",
      "modality_with_params_renamer['uniform'] = 'uniform\\n$\\\\alpha=1$\\n$\\\\beta=1$'\n",
      "model_data = model_data.rename(columns=modality_with_params_renamer)\n",
      "\n",
      "sns.violinplot(model_data, bw=0.2, color=colors)\n",
      "ax.set_ylim(0, 1)\n",
      "ax.set_ylabel('$\\Psi$')\n",
      "ax.set_yticks([0, 0.5, 1])\n",
      "sns.despine()\n",
      "fig.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parameterizations of Bayesian model"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We will employ a Bayesian model to do a (very non-exhaustive) \"grid search\" of parameter space for splicing events. Meaning, given a particular splicing event, does it match one of these modalities' parameterizations?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ncols = len(modality_estimator.models['included'].alphas)\n",
      "nrows = len(modality_estimator.models)\n",
      "\n",
      "fig, axes = plt.subplots(nrows=nrows, ncols=1, figsize=(2*ncols, 4*nrows))\n",
      "\n",
      "n = 10000\n",
      "\n",
      "for ax, (model_name, model) in zip(axes, modality_estimator.models.items()):\n",
      "    parameterizations = [rv.rvs(n) for rv in model.rvs]\n",
      "    color = modality_visualizer.modality_colors[model_name]\n",
      "    xticklabels = ['$\\\\alpha={:.3f}$\\n$\\\\beta={:.3f}$'.format(a, b) for a, b in zip(model.alphas, model.betas)]\n",
      "    sns.violinplot(parameterizations, bw=0.2, color=color, names=xticklabels, #color=colors, \n",
      "                   ax=ax)\n",
      "    ax.set_ylim(0, 1)\n",
      "    ax.set_ylabel('$\\Psi$')\n",
      "    ax.set_yticks([0, 0.5, 1])\n",
      "    ax.set_title(model_name)\n",
      "fig.tight_layout()\n",
      "sns.despine()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prior probability on parameterizations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use a uniform prior on all parameterizations except the *bimodal* distribution. This is because through extensive testing, we have found that using a uniform prior on the *bimodal* distribution causes slightly noisy (+10% uniform noise) *included* and *excluded* splicing events to be called \"bimodal,\" and we want to eliminate false postives in the *bimodal* category."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(nrows=nrows, ncols=1, figsize=(2*ncols, 4*nrows), sharey=True)\n",
      "\n",
      "n = 10000\n",
      "\n",
      "n_params = 10\n",
      "\n",
      "for ax, (model_name, model) in zip(axes, modality_estimator.models.items()):\n",
      "    color = modality_visualizer.modality_colors[model_name]\n",
      "    if model_name == 'bimodal':\n",
      "        ymax = np.exp(np.arange(len(modality_estimator.parameters))).astype(float)\n",
      "        ymax = ymax/ymax.sum()\n",
      "    else:\n",
      "        ymax = np.ones(len(modality_estimator.parameters)).astype(float)/len(modality_estimator.parameters)\n",
      "    ymin = np.zeros(ymax.shape)\n",
      "    x = np.arange(ymax.shape[0])\n",
      "    ax.plot(x, ymax, 'o-', color=color, linewidth=5, markersize=20)\n",
      "    ax.fill_between(x, ymin, ymax, color=color, alpha=0.75)\n",
      "    ax.set_xlim(0, x.max())\n",
      "    xticklabels = ['$\\\\alpha={:.3f}$\\n$\\\\beta={:.3f}$'.format(a, b) for a, b in zip(model.alphas, model.betas)]\n",
      "    ax.set_xticks(x)\n",
      "\n",
      "    ax.set_ylabel('Prior probability')\n",
      "\n",
      "    ax.set_xticklabels(xticklabels)\n",
      "    ax.set_xlim(x.min()-0.5, x.max()+0.5)\n",
      "    ax.set_title(model_name)\n",
      "    \n",
      "fig.tight_layout()\n",
      "sns.despine()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing modality estimation"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "To show that this framework is accurate, we start with a \"perfect\" event, which uses the last parameterization of each model, which is the \"most extreme\" version of that model under our assumptions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 100\n",
      "event = pd.Series(modality_estimator.inclusion_model.rvs[-1].rvs(n))\n",
      "\n",
      "\n",
      "sns.set(style='ticks')\n",
      "fig, ax = plt.subplots(figsize=(2, 4))\n",
      "sns.violinplot(event, ax=ax, bw=0.2, color=modality_visualizer.modality_colors['included'])\n",
      "ax.set_ylim(0, 1)\n",
      "ax.set_yticks([0, 0.5, 1])\n",
      "sns.despine()\n",
      "fig.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Let's estimate the modality of this event by calculating the log-likelihood of each parameterization using ``modality_estimator._loglik``, and summing the results using ``modality_estimator._logsumexp``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logliks = modality_estimator._loglik(event)\n",
      "logsumexps = modality_estimator._logsumexp(logliks)\n",
      "\n",
      "# Visualize the events\n",
      "plotter = modality_visualizer.event_estimation(event, logliks, logsumexps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The left panel shows a violinplot of the event. The middle panel shows the log-likelihoods of different models at increasing parameterizations. The right panel shows the total summed `Bayes factors <http://en.wikipedia.org/wiki/Bayes_factor>`_ of how much more likely a model is over the uniform distribution, where the cutoff for a guessing that something is a uniform distribution is a $\\log_2\\left(\\text{Bayes factor}\\right) > 3$.\n",
      "\n",
      "Let's add add random noise to the \"perfect\" included event, and see how that changes the modality estimation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.set(style='ticks')\n",
      "fig, ax = plt.subplots(figsize=(2, 4))\n",
      "event_noisy = event.copy()\n",
      "event_noisy[:50] = np.random.uniform(size=50)\n",
      "\n",
      "sns.violinplot(event_noisy, ax=ax, bw=0.2, color=modality_visualizer.modality_colors['included'])\n",
      "ax.set_ylim(0, 1)\n",
      "ax.set_yticks([0, 0.5, 1])\n",
      "\n",
      "sns.despine()\n",
      "fig.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logliks = modality_estimator._loglik(event_noisy)\n",
      "logsumexps = modality_estimator._logsumexp(logliks)\n",
      "\n",
      "# Visualize the events\n",
      "plotter = modality_visualizer.event_estimation(event_noisy, logliks, logsumexps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The included modality becomes less likely, but it still beats out the uniform and bimodal distributions, which is what we want.\n",
      "\n",
      "Let's use this idea of noise to estimate modalities. We'll use 100 cells total, and do 3 iterations of adding noise at 0%, 25%, and 50%. We will visualize each estimation using the same ``modality_visualizer`` for the parameterizations. This will output quite a few plots."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We will be writing incrementally to this \"modality_guesses\" file, because if\n",
      "# this is done with many iterations and many noise levels, the file gets too\n",
      "# big and the IPython kernel crashes\n",
      "modality_guesses_csv = 'modality_guesses.csv'\n",
      "\n",
      "# ALways start fresh with a new csv file\n",
      "try:\n",
      "    os.remove(modality_guesses_csv)\n",
      "except OSError:\n",
      "    pass\n",
      "\n",
      "n_cells = 100\n",
      "n_cell = n_cells\n",
      "n_noisys = (0, 25, 50)\n",
      "\n",
      "columns = ['prior', 'true_modality', 'guessed_modality', 'n_rogue', 'iteration']\n",
      "\n",
      "df = pd.DataFrame(columns=columns)\n",
      "df.to_csv(modality_guesses_csv, index=False)\n",
      "\n",
      "for n_noisy in n_noisys:\n",
      "    for i in range(5):\n",
      "        rows = []\n",
      "        for model_name, model in modality_estimator.models.items():\n",
      "            rv = model.rvs[-1]\n",
      "            event = pd.Series(rv.rvs(n_cells))\n",
      "            event.name = 'True modality: {}'.format(model_name)\n",
      "\n",
      "            event[:n_noisy] = np.random.uniform(size=n_noisy)\n",
      "            \n",
      "            n = len(modality_estimator.bimodal_model.prob_parameters)\n",
      "\n",
      "            logliks = modality_estimator._loglik(event)\n",
      "            logsumexps = modality_estimator._logsumexp(logliks)\n",
      "            \n",
      "            # Visualize the events\n",
      "            plotter = modality_visualizer.event_estimation(event, logliks, logsumexps)\n",
      "            filename = '{}_nnoisy{}_iter{}_bimodal_exponential_other_uniform_prior.pdf'.format(model_name, n_cell, n_noisy, i)\n",
      "            plotter.fig.savefig(filename)\n",
      "            rows.append(['bimodal_exponential_other_uniform', model_name, logsumexps.argmax(), n_noisy, i])\n",
      "\n",
      "        modality_guesses = pd.DataFrame(rows, columns=columns)\n",
      "        with open(modality_guesses_csv, 'a') as f:\n",
      "            modality_guesses.to_csv(f, header=False, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Now let's plot the accuracy of the model on the increasingly noisy splicing events and their modality estimations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modality_guesses = pd.read_csv(modality_guesses_csv)\n",
      "\n",
      "model_accuracy = modality_guesses.groupby(['prior', 'n_rogue', \n",
      "                                           'true_modality']).apply(lambda x: (x.true_modality == x.guessed_modality).sum())/n_noisys.max()*n_cells\n",
      "model_accuracy = model_accuracy.reset_index()\n",
      "model_accuracy = model_accuracy.rename(columns={0: 'percentage'})\n",
      "fg = sns.factorplot('n_rogue', col='prior', data=model_accuracy, y='percentage', hue='true_modality',\n",
      "               hue_order=('excluded', 'middle', 'included', 'bimodal'), palette='deep', kind='point')\n",
      "fg.fig.savefig('percent_noise_vs_true_positives.pdf')\n",
      "\n",
      "\n",
      "false_positives = modality_guesses.groupby(['prior', 'n_rogue', \n",
      "                                            'guessed_modality', 'true_modality']).apply(lambda x: (x.true_modality != x.guessed_modality).sum())/50\n",
      "# false_positives = false_positives.unstack()\n",
      "false_positives = false_positives.reset_index()\n",
      "false_positives = false_positives.rename(columns={0: 'counts'})\n",
      "false_positives.head()\n",
      "\n",
      "fg = sns.factorplot('n_rogue', y='counts', row='prior', col='true_modality', hue='guessed_modality', data=false_positives,\n",
      "               hue_order=('excluded', 'middle', 'included', 'bimodal', 'uniform'), palette='deep', size=6)\n",
      "fg.fig.savefig('percent_noise_vs_false_positives_factorplot.pdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The \"middle\" modalities become less accurate at about 30% noise, but from looking at the events, I'm happy with these getting \"mis-categorized\" because they do truly look like \"uniform\" events."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}